---
title: Usage
---

# Usage

## Installation

Use a modern Python (>=3.10) and install via `pip` in a virtualenv. Poppler is
recommended for PDF rasterization.

```
pip install .
# Optional: docs build dependencies
pip install .[docs]
```

Dependencies you may need:

- Poppler (for pdf2image): macOS `brew install poppler`, Debian/Ubuntu `apt-get install poppler-utils`
- Tesseract OCR: macOS `brew install tesseract`, Debian/Ubuntu `apt-get install tesseract-ocr`
- Optional: PyMuPDF (`pip install pymupdf`) as a fallback when Poppler is not available

## Command-line

Redact a PDF or image:

```
evanesco run -i data/in/pii_basic.pdf -o data/out/redacted.pdf \
  --use-llm True --spacy-model en_core_web_lg
```

Launch the web UI:

```
evanesco ui --host 0.0.0.0 --port 7860
# or
evanesco-ui
# or (uses the exact Python of your venv)
python -m evanesco.cli ui --host 0.0.0.0 --port 7860
```

The UI can also generate review CSVs (candidates and boxes) to support
human-in-the-loop workflows.

## Python API

```python
from evanesco.core import RunConfig, process_path

cfg = RunConfig(use_llm=False, spacy_model="en_core_web_lg")
res = process_path("input.pdf", "output.redacted.pdf", cfg)
print(res["out"])
```

### Pipeline internals

Each run returns structured metadata so you can inspect every decision:

- `pages[*].candidates` - spans generated by spaCy/regex/optional LLM NER before confirmation. Each includes detector source, label, character offsets, and text.
- `pages[*].llm_json` - parsed confirmation payload with model, decision (`redact`), category, score, and explanation. When traces are enabled this also includes the raw prompt/response under `trace`.
- `pages[*].boxes` - OCR-aligned bounding boxes for accepted spans (toggle `track_reasons=True` from code or enable review CSVs in the UI).
- `pages[*].timings` - per-stage timings (OCR, detection, LLM, alignment, redaction, total). The UI aggregates these for the Performance panel.

### Outputs & artifacts

Artifacts produced alongside the PDF:

- `<output>.meta.json` - the same payload returned by `process_path`, including per-page timings and detector outputs.
- `<output>.audit.json` - immutable audit record with input/output hashes, configuration snapshot, policy used, and LLM metrics. The audit writer also records whether a policy allowed each category.
- `artifacts/<output_stem>.ocr.zip` - per-page TSV exports from Tesseract when `export_ocr_debug` is enabled (default `True` for the CLI; toggle exposed in the UI).
- `artifacts/<output_stem>.all_text.txt` - concatenated OCR text, handy for grepping specific spans.
- `<output_stem>.previews/` - overlay PNGs showing accepted boxes (green) and rejected candidates (red) when `generate_previews` is enabled (default `True` in the UI).
- `<output_stem>.traces/` - one JSON per page containing the full LLM prompt/response when `explain_traces` is enabled.
- Review CSVs (`.candidates.csv`, `.boxes.csv`, `.llm_items.csv`) - generated from the UI or by calling the review helpers in automation to support human QA workflows.

### LLM tuning knobs

- `llm_ner_model` / `--llm-ner-model` - default `gemma3:4b` few-shot extractor (falls back to built-in prompt if none supplied).
- `llm_model` / `--llm-model` - default `gpt-oss:20b` confirmation model; swap for lighter models when latency matters.
- `llm_timeout` / `--llm-timeout` - cap request times per call.
- `llm_ner_chunk_chars` - limit characters per request to protect smaller models.
- `prompt_path` / `--prompt-path` - override the confirmation prompt JSONL. Similarly `llm_ner_prompt_path` points at the few-shot prompt.

### Parallelism

Use `--workers` on the CLI (or set `RunConfig.workers`) to parallelize pages on multi-core machines. OCR remains CPU-bound, so keep an eye on total system resources when increasing this value.

## Policies

Use a built-in policy or provide a custom YAML:

```
evanesco run -i input.pdf -o out.pdf --policy gdpr
# or
evanesco run -i input.pdf -o out.pdf --policy configs/policies/custom.yaml
```

YAML example:

```
name: custom
allowed_categories: [PERSON, EMAIL, PHONE]
default_redact: true
```

## Pseudonymization Mode

Overlay category labels instead of pure black boxes:

```
evanesco run -i input.pdf -o out.pdf --mode label
```

## Batch Processing

```
evanesco batch --input-dir data/in --output-dir data/out --workers 4

## OCR Tuning

Hard scans benefit from higher DPI (default 400), preprocessing, deskew and
auto-PSM retries. These are enabled by default and can be toggled:

```
evanesco run -i input.pdf -o out.pdf \
  --preprocess/--no-preprocess \
  --deskew/--no-deskew \
  --binarize/--no-binarize \
  --auto-psm/--no-auto-psm \
  --dpi 450 --psm 6
```

## Multilingual (French)

spaCy supports many languages including French. For French documents:

- Install the French spaCy model: `python -m spacy download fr_core_news_lg`
- Ensure Tesseract has French language data (usually `fra`); on Debian/Ubuntu: `apt-get install tesseract-ocr-fra`
- Run with French OCR language and model:

```
evanesco run -i input.pdf -o out.pdf --lang fra --spacy-model fr_core_news_lg
```

You can also let the CLI pick a model based on `--lang` by using auto:

```
evanesco run -i input.pdf -o out.pdf --lang fra --spacy-model auto
```

In the UI, set "Tesseract language" to `fra` and "spaCy model" to `fr_core_news_lg`.
```

## REST API

Install server extras and run the API:

```
pip install .[server]
evanesco-api --host 0.0.0.0 --port 8000
```

Once the server is running the interactive Swagger UI lives at
`http://localhost:8000/docs` (ReDoc is exposed at `/redoc`). The API now models
redaction as jobs so you can track inputs, outputs, and status transitions.

Create a job that reads a local file path and writes the redacted PDF to the
default `artifacts/redactions/` directory. Adjust the payload to toggle
detectors or policy paths:

```
curl -X POST http://localhost:8000/jobs \
  -H "Content-Type: application/json" \
  -d '{
        "input_path": "data/in/pii_basic.pdf",
        "options": {
          "use_spacy": true,
          "use_llm": false,
          "policy_path": "configs/default.yaml"
        }
      }'
```

Each response contains a job identifier. Inspect and download artefacts via the
CRUD endpoints:

```
# List jobs
curl http://localhost:8000/jobs

# Inspect a single job
curl http://localhost:8000/jobs/<job-id>

# Download the redacted PDF once the job status is "completed"
curl -L http://localhost:8000/jobs/<job-id>/download -o redacted.pdf
```

For browser uploads (or when paths are inconvenient) submit a multipart request
to the `/jobs/upload` endpoint. Optional redaction settings are supplied as a
JSON document in the `options` field:

```
curl -X POST http://localhost:8000/jobs/upload \
  -F "file=@data/in/pii_basic.pdf" \
  -F "options={\"use_spacy\":true,\"use_llm\":false}"
```

The legacy `/redact` endpoint is still available but simply forwards to
`/jobs/upload`; plan to migrate clients to the jobs workflow.

Prometheus metrics remain exposed at `/metrics` when `prometheus-client` is installed.

## LLM Explainability

When LLM confirmation is enabled, Evanesco captures per-item explanations and timing metrics:

- Each item includes: `text`, `start`, `end`, `category`, `redact`, `why`, `score`.
- Per-page metadata includes model and basic timing counts from the LLM backend.
- The UI has an "LLM Explainability" panel showing the extracted items.
- Review CSVs include an `llm_items.csv` with the same fields.

Notes:
- `EVANESCO_DEBUG=1` adds more loader details and can help troubleshooting.
- Prompts are summarized in the metadata via short excerpts; full prompts can be reconstructed from the run inputs.

## Visual Previews

Enable preview overlays (kept=green, rejected=red) in the UI under "Review & Artifacts".
Use the page slider to browse per-page QA images. Previews are also saved next to
the output under a `.previews` folder.

## Full LLM Traces (optional)

For deep audits, enable "Save full LLM traces" in the UI to write one JSON per
page containing the full prompt and raw LLM response in a `.traces` folder
alongside the output PDF.

## Performance Monitoring

The UI exposes a "Performance" panel with per-stage timings (OCR, detect, LLM,
align, redact) and averages across pages. Use this to spot bottlenecks.

## Audit and Integrity

Every run writes an audit JSON next to the output PDF with input/output hashes,
config snapshot, and page summaries. To add a tamper-evident signature, set an
HMAC key:

```
export EVANESCO_HMAC_KEY="a-strong-secret"
```

## Troubleshooting: spaCy model not found

If you see a warning about `en_core_web_lg` not found while the model is
installed, it means the running Python is not your venv's interpreter.

- Verify the interpreter: `python -c "import sys; print(sys.executable)"`
- Verify the `evanesco` script is from your venv: `which evanesco`
- Prefer launching the UI with your venv's Python:
  `python -m evanesco.cli ui --host 0.0.0.0 --port 7860`
- Enable debug details: `EVANESCO_DEBUG=1 ...`
- As a workaround, pass the model by path in the UI or CLI `--spacy-model`.

## LLM NER (Few-shot)

Use the LLM to extract entities with a few-shot prompt instead of spaCy:

```
evanesco run -i input.pdf -o out.pdf --no-use-spacy --use-llm-ner \
  --llm-ner-prompt src/prompts/ner_fewshot.jsonl
```

In the UI, enable "Use LLM NER (few-shot instead of spaCy)" and optionally
provide a prompt path. The system falls back to a built-in prompt if none is
provided.
